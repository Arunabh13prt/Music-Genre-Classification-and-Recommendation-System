{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPG2pLmJcrOm5cXHdubz4/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arunabh13prt/Music-Genre-Classification-and-Recommendation-System/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEaxb0fTtCGl",
        "outputId": "6aae7406-3886-43f1-ba36-595e336b4fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Processing: blues\n",
            "\n",
            "Processing: hiphop\n",
            "\n",
            "Processing: disco\n",
            "\n",
            "Processing: rock\n",
            "\n",
            "Processing: jazz\n",
            "\n",
            "Processing: reggae\n",
            "\n",
            "Processing: metal\n",
            "\n",
            "Processing: classical\n",
            "\n",
            "Processing: pop\n",
            "\n",
            "Processing: country\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import librosa\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "DATASET_PATH = \"/content/drive/My Drive/GTZAN/genres_original\"\n",
        "JSON_PATH = \"/content/drive/My Drive/mfcc.json\"\n",
        "SAMPLE_RATE = 22050\n",
        "DURATION = 30  # in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
        "\n",
        "# Data augmentation\n",
        "def time_stretch(signal, rate=1.0):\n",
        "    return librosa.effects.time_stretch(signal, rate=rate)\n",
        "\n",
        "def pitch_shift(signal, sr, n_steps):\n",
        "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
        "\n",
        "def add_noise(signal, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(signal))\n",
        "    augmented_signal = signal + noise_factor * noise\n",
        "    return augmented_signal\n",
        "\n",
        "# Extracting MFCCs\n",
        "def extract_mfccs(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=10):\n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"mfcc\": [],\n",
        "        \"labels\": [],\n",
        "        \"paths\": []\n",
        "    }\n",
        "\n",
        "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length)\n",
        "\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "        if dirpath != dataset_path:\n",
        "            dirpath_components = dirpath.split(\"/\")\n",
        "            semantic_label = dirpath_components[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            for f in filenames:\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                for d in range(num_segments):\n",
        "                    start = num_samples_per_segment * d\n",
        "                    finish = start + num_samples_per_segment\n",
        "\n",
        "                    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "                    if len(mfcc[0]) == expected_num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc.T.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        data[\"paths\"].append(file_path)\n",
        "\n",
        "                    # Applying augmentations\n",
        "                    signal_augmented = time_stretch(signal[start:finish], rate=1.2)\n",
        "                    mfcc_augmented = librosa.feature.mfcc(y=signal_augmented, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                    if len(mfcc_augmented[0]) == expected_num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc_augmented.T.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        data[\"paths\"].append(file_path)\n",
        "\n",
        "                    signal_augmented = pitch_shift(signal[start:finish], sr=sr, n_steps=4)\n",
        "                    mfcc_augmented = librosa.feature.mfcc(y=signal_augmented, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                    if len(mfcc_augmented[0]) == expected_num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc_augmented.T.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        data[\"paths\"].append(file_path)\n",
        "\n",
        "                    signal_augmented = add_noise(signal[start:finish])\n",
        "                    mfcc_augmented = librosa.feature.mfcc(y=signal_augmented, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                    if len(mfcc_augmented[0]) == expected_num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc_augmented.T.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        data[\"paths\"].append(file_path)\n",
        "\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "\n",
        "# Run the preprocessing\n",
        "extract_mfccs(DATASET_PATH, JSON_PATH)\n"
      ]
    }
  ]
}